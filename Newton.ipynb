{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def const_step(gradient, x, **kwargs):\n",
    "    return kwargs[\"step\"]\n",
    "\n",
    "def iteration_step(gradient, x, **kwargs):\n",
    "    return 1 / (np.sqrt(kwargs[\"iteration\"] + 1))\n",
    "\n",
    "def GradientDescent(f, gradf, x0, epsilon, num_iter, alpha_search, **kwargs):\n",
    "    x = x0.copy()\n",
    "    iteration = 0\n",
    "    grad_norms = []\n",
    "    timestamps = []\n",
    "    alpha = 1\n",
    "    opt_arg = {\"f\": f, \"grad_f\": gradf, \"epsilon\": epsilon, \n",
    "               \"iteration\": iteration}\n",
    "    for arg in kwargs:\n",
    "        opt_arg[arg] = kwargs[arg]\n",
    "    start = timer()\n",
    "    while opt_arg[\"iteration\"] < num_iter:\n",
    "        gradient = gradf(x)\n",
    "        alpha = alpha_search(gradient, x, **opt_arg)\n",
    "        x = x - alpha * gradient\n",
    "        opt_arg[\"iteration\"] += 1\n",
    "        grad_norms.append(np.linalg.norm(gradf(x)))\n",
    "        curr = timer()\n",
    "        timestamps.append((curr - start) * 1000)\n",
    "        if np.linalg.norm(gradf(x)) < epsilon:\n",
    "            break\n",
    "    end = timer()\n",
    "    time = (end - start) * 1000\n",
    "    result = {\"x\": x, \"grad_norms\": grad_norms, \n",
    "              \"num_iter\": len(grad_norms), \"time\": time, \n",
    "              \"time_per_iter\": time / len(grad_norms), \n",
    "              \"timestamps\": timestamps}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[3.0, -1.0], [-2.0, 2.0]])\n",
    "b = np.array([4.0, -12.0])\n",
    "def f(x):\n",
    "    return x @ A @ x - b @ x\n",
    "def gradf(x):\n",
    "    return (A + A.T) @ x - b\n",
    "def hessf(x):\n",
    "    return (A + A.T)\n",
    "x = [1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6., -3.],\n",
       "       [-3.,  4.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hessf(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pure(**kwargs):\n",
    "    return 1\n",
    "\n",
    "def damped(**kwargs):\n",
    "    return kwargs['alpha']\n",
    "\n",
    "def func_conv(x, **kwargs):\n",
    "    return np.linalg.norm(kwargs['f'](x) - kwargs['f_true'](x))\n",
    "\n",
    "def grad_conv(x, **kwargs):\n",
    "    return np.linalg.norm(kwargs['gradf'](x))\n",
    "\n",
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpmath import euler\n",
    "emc = float(euler)\n",
    "gum_loc = 2\n",
    "norm_loc = 4\n",
    "def f_stat(x):\n",
    "    c2 = (1 + np.pi ** 2 / 6 + emc ** 2)\n",
    "    c1 = 2 * emc * (norm_loc - gum_loc)\n",
    "    c0 = (norm_loc - gum_loc) ** 2\n",
    "    return x[0] ** 2 * c2 - x[0] * c1 + c0\n",
    "\n",
    "def gradf_stat(x):\n",
    "    c1 = 2 * (1 + np.pi ** 2 / 6 + emc ** 2)\n",
    "    c0 = 2 * emc * (norm_loc - gum_loc)\n",
    "    return np.array([x[0] * c1 - c0])\n",
    "\n",
    "def hessf_stat(x):\n",
    "    c1 = 2 * (1 + np.pi ** 2 / 6 + emc ** 2)\n",
    "    return np.array([c1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_rosenbrock(x):\n",
    "    x1, x2 = x\n",
    "    return 100 * (x2 - x1**2)**2 + (1 - x1)**2\n",
    "\n",
    "def gradf_rosenbrock(x):\n",
    "    x1, x2 = x\n",
    "    return np.array([400 * x1 * (x1**2 - x2) + 2 * (x1 - 1), 200 * (x2 - x1**2)])\n",
    "\n",
    "def hessf_rosenbrock(x):\n",
    "    x1, x2 = x\n",
    "    a12 = -400 * x1\n",
    "    return np.array([[1200 * x1**2 - 400 * x2 + 2, a12],\n",
    "                     [a12, 200]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Newton(f, gradf, hessf, x0, epsilon, num_iter,\n",
    "           step_selection=pure, convergence=grad_conv, **kwargs):\n",
    "    x = x0.copy()\n",
    "    iteration = 0\n",
    "    opt_args = {\"f\": f, \"gradf\": gradf}\n",
    "    opt_args.update(kwargs)\n",
    "    conv_values = []\n",
    "    timestamps = []\n",
    "    start = timer()\n",
    "    while iteration < num_iter:\n",
    "        alpha = step_selection(**kwargs)\n",
    "        if len(x) > 1:\n",
    "            x = x + alpha * np.linalg.solve(hessf(x), -gradf(x))\n",
    "        else:\n",
    "            x = x - alpha * 1 / hessf(x)[0] * gradf(x)[0]\n",
    "        conv_value = convergence(x, **opt_args)\n",
    "        conv_values.append(conv_value)\n",
    "        curr = timer()\n",
    "        timestamps.append((curr - start) * 1000)\n",
    "        if conv_value < epsilon:\n",
    "            break\n",
    "        iteration += 1\n",
    "\n",
    "    end = timer()\n",
    "    time = (end - start) * 1000\n",
    "    result = {\"x\": x, \"conv_values\": conv_values, \n",
    "              \"num_iter\": len(conv_values), \"time\": time, \n",
    "              \"time_per_iter\": time / len(conv_values), \n",
    "              \"timestamps\": timestamps}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Newton(f_stat, gradf_stat, hessf_stat, [1000], 10**-15, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['num_iter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3104009992966894"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': array([1., 1.]),\n",
       " 'conv_values': [1997.99999,\n",
       "  446336269.49103916,\n",
       "  9.358498706328142e-05,\n",
       "  9.78328419189108e-07,\n",
       "  0.0],\n",
       " 'num_iter': 5,\n",
       " 'time': 4.030287000205135,\n",
       " 'time_per_iter': 0.806057400041027,\n",
       " 'timestamps': [2.787761000035971,\n",
       "  3.143775999888021,\n",
       "  3.445149999606656,\n",
       "  3.739613000107056,\n",
       "  4.024318999654497]}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
